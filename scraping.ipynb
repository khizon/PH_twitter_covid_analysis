{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84f21cb",
   "metadata": {},
   "source": [
    "# Scraping Tweets from a public Twitter account between two dates\n",
    "\n",
    "The twitter API has a functionality of scraping tweets from a public Twitter account but it is returns only a limited number of recent tweets. Another library, snscrape can be used to scrape historical tweets but it truncates the tweet content when outputting the JSON file (not sure if I just made a mistake). Using both libraries together, can avoid both of their limitations. We use snscrape to gather the URLs of the tweets, and then use the twitter API to scrape the actual tweets.\n",
    "\n",
    "To setup your twitter developer account and get the API keys, click [here](https://www.youtube.com/watch?v=Lu1nskBkPJU&t=897s).\n",
    "\n",
    "The `config.ini` file contains the API keys. It looks similar to this:\n",
    "```\n",
    "[twitter]\n",
    "\n",
    "api_key = xxxxxxxxxxxxxxxx\n",
    "api_key_secret = xxxxxxxxxxxxxxxx\n",
    "\n",
    "access_token = xxxxxxxxxxxxxxxx\n",
    "access_token_secret = xxxxxxxxxxxxxxxx\n",
    "```\n",
    "Next, run the snscrape script on the terminal:\n",
    "\n",
    "`snscrape --progress --since 2019-10-01 twitter-search \"from:inquirerdotnet until:2021-08-04\" > twitter_inquirerdotnet.txt`\n",
    "\n",
    "This lets you set the date range and twitter username. The tweet urls will be saved on a text file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e45fa72-7ec7-4be2-a5a2-f4c1e8d7f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get Config\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a409c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tweepy():\n",
    "    auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f9f7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the snscrape output\n",
    "url_df = pd.read_csv('twitter_inquirerdotnet.txt', index_col=None, header=None, names=['links'])\n",
    "\n",
    "#Extract the tweet id\n",
    "af = lambda x: x['links'].str.split(\"/\").str[-1]\n",
    "url_df['tweet_id'] = url_df['links'].str.split('/').str[-1]\n",
    "\n",
    "# Convert Id to list\n",
    "ids = url_df['tweet_id'].tolist()\n",
    "\n",
    "# Process the ids by batch or chunks of 100\n",
    "total_count = len(ids)\n",
    "chunks = (total_count-1) // 100 + 1\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "461a8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the tweets along with some other data\n",
    "def fetch_tw(ids, name=\"jack\"):\n",
    "    api = setup_tweepy()\n",
    "    # tweet_mode = \"extended\" (280 characters)\n",
    "    tweets = api.lookup_statuses(ids, tweet_mode= \"extended\")\n",
    "    tweet_df = pd.DataFrame()\n",
    "    for tweets in tweets:\n",
    "        tweet_elem = {\"tweet_id\": status.id,\n",
    "                      \"screen_name\": status.user.screen_name,\n",
    "                      \"Tweet\":status.full_text,\n",
    "                      \"Date\":status.created_at,\n",
    "                      \"retweet_count\": status.retweet_count,\n",
    "                      \"favorite_count\": status.favorite_count}\n",
    "        # append tweet to dataframe of tweets\n",
    "        tweet_df = tweet_df.append(tweet_elem, ignore_index = True)\n",
    "    # continously append new data to the csv\n",
    "    tweet_df.to_csv(f\"tweets_{name}.csv\", mode=\"a\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c179ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2075/2075 [1:43:21<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a loop to fetch the tweets on batches of 100. I used tqdm to show the progress\n",
    "for i in tqdm(range(chunks)):\n",
    "    batch = ids[i*100:(i+1)*100]\n",
    "    result = fetch_tw(batch, name='inquirerdotnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90f021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209478 entries, 0 to 209477\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   tweet_id        209478 non-null  object\n",
      " 1   screen_name     209478 non-null  object\n",
      " 2   Tweet           209478 non-null  object\n",
      " 3   Date            209478 non-null  object\n",
      " 4   retweet_count   209478 non-null  object\n",
      " 5   favorite_count  209478 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 9.6+ MB\n"
     ]
    }
   ],
   "source": [
    "inquirer_df = pd.read_csv('tweets_inquirerdotnet.csv')\n",
    "inquirer_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d531e0fa8e0794bb7f384be6310a043246fe1c78165b5e565fbe0e56857c19ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
